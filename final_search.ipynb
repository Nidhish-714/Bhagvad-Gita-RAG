{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CodingStuff\\Bhagvad-Gita-RAG\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from rank_bm25 import BM25Okapi\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "class HybridSearch:\n",
    "    def __init__(self, mongo_uri, pinecone_instance, model_name='all-MiniLM-L6-v2'):\n",
    "        # Initialize MongoDB connection\n",
    "        self.mongo_client = MongoClient(mongo_uri)\n",
    "        self.db = self.mongo_client['mytestdb']\n",
    "        self.collection = self.db['collection']\n",
    "        \n",
    "        # Initialize Pinecone\n",
    "        self.pinecone_index = pinecone_instance\n",
    "        \n",
    "        # Initialize sentence transformer model\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        \n",
    "        # Download required NLTK data\n",
    "        nltk.download('punkt')\n",
    "        nltk.download('stopwords')\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        # Convert to lowercase and remove special characters\n",
    "        text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "        # Tokenize\n",
    "        tokens = word_tokenize(text)\n",
    "        # Remove stopwords\n",
    "        tokens = [token for token in tokens if token not in self.stop_words]\n",
    "        return tokens\n",
    "\n",
    "    def create_vector_embeddings(self):\n",
    "        \"\"\"Create and store vector embeddings for all documents in Pinecone\"\"\"\n",
    "        documents = self.collection.find({}, {'_id': 1, 'fullplot': 1})\n",
    "        \n",
    "        for doc in documents:\n",
    "            if 'fullplot' in doc and doc['fullplot']:\n",
    "                # Generate embedding\n",
    "                embedding = self.model.encode(doc['fullplot']).tolist()\n",
    "                \n",
    "                # Store in Pinecone with MongoDB _id as metadata\n",
    "                self.pinecone_index.upsert(\n",
    "                    vectors=[{\n",
    "                        'id': str(doc['_id']),\n",
    "                        'values': embedding,\n",
    "                        'metadata': {'mongo_id': str(doc['_id'])}\n",
    "                    }]\n",
    "                )\n",
    "\n",
    "    def hybrid_search(self, query, top_k=5, alpha=0.5):\n",
    "        \"\"\"\n",
    "        Perform hybrid search using both sparse and dense retrieval\n",
    "        alpha: weight for combining scores (0-1), higher value gives more weight to dense retrieval\n",
    "        \"\"\"\n",
    "        # Generate query embedding for dense retrieval\n",
    "        query_embedding = self.model.encode(query).tolist()\n",
    "        \n",
    "        # Perform dense retrieval using Pinecone\n",
    "        dense_results = self.pinecone_index.query(\n",
    "            vector=query_embedding,\n",
    "            top_k=top_k,\n",
    "            include_metadata=True\n",
    "        )\n",
    "\n",
    "        # Perform sparse retrieval using BM25\n",
    "        # First, get all documents\n",
    "        documents = list(self.collection.find({}, {'_id': 1, 'fullplot': 1}))\n",
    "        \n",
    "        # Preprocess documents for BM25\n",
    "        processed_docs = [self.preprocess_text(doc['fullplot']) for doc in documents if 'fullplot' in doc]\n",
    "        bm25 = BM25Okapi(processed_docs)\n",
    "        \n",
    "        # Get BM25 scores\n",
    "        processed_query = self.preprocess_text(query)\n",
    "        bm25_scores = bm25.get_scores(processed_query)\n",
    "        \n",
    "        # Normalize BM25 scores\n",
    "        bm25_scores = (bm25_scores - np.min(bm25_scores)) / (np.max(bm25_scores) - np.min(bm25_scores))\n",
    "        \n",
    "        # Create a dictionary of dense scores\n",
    "        dense_scores = {\n",
    "            match.metadata['mongo_id']: match.score \n",
    "            for match in dense_results.matches\n",
    "        }\n",
    "        \n",
    "        # Combine scores\n",
    "        final_scores = []\n",
    "        for i, doc in enumerate(documents):\n",
    "            doc_id = str(doc['_id'])\n",
    "            dense_score = dense_scores.get(doc_id, 0)\n",
    "            sparse_score = bm25_scores[i]\n",
    "            \n",
    "            # Combine scores using weighted average\n",
    "            combined_score = (alpha * dense_score) + ((1 - alpha) * sparse_score)\n",
    "            final_scores.append((doc, combined_score))\n",
    "        \n",
    "        # Sort by combined score and return top_k results\n",
    "        final_results = sorted(final_scores, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "        \n",
    "        return final_results\n",
    "\n",
    "    def search(self, query, top_k=5, alpha=0.5):\n",
    "        \"\"\"Wrapper method for performing search and returning formatted results\"\"\"\n",
    "        results = self.hybrid_search(query, top_k, alpha)\n",
    "        formatted_results = []\n",
    "        \n",
    "        for doc, score in results:\n",
    "            formatted_results.append({\n",
    "                'id': doc['_id'],\n",
    "                'fullplot': doc['fullplot'],\n",
    "                'score': score\n",
    "            })\n",
    "            \n",
    "        return formatted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.5127036362877593\n",
      "Text: Arjun continues with his glorification of Shree Krishna by declaring him as ananta-vīrya (possessing infinite strength) and ananta-vikramaḥ (immeasurably powerful). Overcome with awe, he offers his sa...\n",
      "---\n",
      "Score: 0.501025734126391\n",
      "Text: Shree Krishna now poses many questions Himself, and asks Arjun to listen carefully to their answers....\n",
      "---\n",
      "Score: 0.501025734126391\n",
      "Text: Shree Krishna now poses many questions Himself, and asks Arjun to listen carefully to their answers....\n",
      "---\n",
      "Score: 0.501025734126391\n",
      "Text: Shree Krishna now poses many questions Himself, and asks Arjun to listen carefully to their answers....\n",
      "---\n",
      "Score: 0.501025734126391\n",
      "Text: Shree Krishna now poses many questions Himself, and asks Arjun to listen carefully to their answers....\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Initialize the hybrid search\n",
    "mongo_uri=\"mongodb+srv://nidhish:nidhish@cluster1.vthss.mongodb.net/?retryWrites=true&w=majority&appName=Cluster1\"\n",
    "from pinecone import Pinecone\n",
    "# pcsk_7Cj4Kj_bK4WbhEpxCM4PJQWLkP8muKcU6eRAN7pSLy2fphFvVr9NXuYY395kHhKo3K6za\n",
    "pc = Pinecone(api_key=\"pcsk_7Cj4Kj_bK4WbhEpxCM4PJQWLkP8muKcU6eRAN7pSLy2fphFvVr9NXuYY395kHhKo3K6za\")\n",
    "\n",
    "index = pc.Index(host=\"https://mydb-j1b0j8k.svc.aped-4627-b74a.pinecone.io\")\n",
    "hybrid_searcher = HybridSearch(mongo_uri, index)\n",
    "\n",
    "# First, create vector embeddings for all documents (run this once)\n",
    "# hybrid_searcher.create_vector_embeddings()\n",
    "\n",
    "# Perform hybrid search\n",
    "query = \"What did Arjuna say to Krishna?\"\n",
    "results = hybrid_searcher.search(query, top_k=5, alpha=0.6)\n",
    "\n",
    "# Print results\n",
    "for result in results:\n",
    "    print(f\"Score: {result['score']}\")\n",
    "    print(f\"Text: {result['fullplot'][:200]}...\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
